break tokenize 
r
r test.c 
n
print lexer.buffer 
n
n
print t
n
n
print lexer->start
print lexer
print *lexer
break tokenize
r
r
r test.c 
n
n
print *lexer
n
print *lexer
reboot
exit
break tokenize
break tokenize 
r ./test.c 
n
n
print *lexer
n
pn
n
print *lexer
n
n
n
n
print *lexer
print *lexer.tokens
print *lexer.tokens 
print *lexer.tokens.tokens 
print *lexer.tokens.tokens @ 1 
print *lexer.tokens.tokens @ 2
print *lexer
print *lexer.buffer[10]
print *lexer.buffer
print *lexer.buffer[1]
print *lexer.buffer + 1
print lexer->buffer
print lexer->buffer[3]
print lexer->buffer[10]
q
b 98
b lexer.c:98
r
r test.c 
print *lexer
 n
n
print *lexer
n
n
n
print *lexer
n
print *lexer
n
print *lexer
n
print *lexer
n
n
print t
n
n
n
n
n
n
n
n
n
n
n
n
n
n
n
n
priny y
print t
n
n
n
n
n
print t
n
n
n
n
print t
n
n
n
n
print t
n
n
n
n
n
n
n
n
n
n
n
n
n
n
print t
n
n
n
n
n
n
n
n
n
n
n
print t
n
n
n
n
n
n
n
n
print t
n
n
n
n
n
n
n
n
n
n
n
n
n
n
n
n
n
n
n
n
n
n
n
n
2
1
q
